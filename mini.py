"""mini.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BFs3qXNkaNB_BjclM9fmcvuM1Kc7pycf
"""

from google.colab import drive
drive.mount('/content/drive')

import zipfile

with zipfile.ZipFile('/content/drive/MyDrive/mini_challenge/train_crop (1).zip') as z:
  z.extractall('')
# name cropped_large

import csv
import numpy as np
import os
import torch
import torchvision
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
import cv2
import pandas as pd
import csv
from PIL import Image

train_csv = '/content/drive/MyDrive/mini_challenge/train.csv'
category_csv = '/content/drive/MyDrive/mini_challenge/category.csv'
train_data_path = '/content/cropped_large'


# Read catergory.csv
label_to_index = {}
index_to_label = {}

# Read the CSV file and populate the dictionaries
with open(category_csv, 'r', newline='') as file:
  reader = csv.reader(file)
  for idx, row in enumerate(reader):
    if idx > 0:
      index, label = row[0], row[1]
      label_to_index[label] = int(index)
      index_to_label[index] = label

# Check
print("Mapping from name to number:")
print(label_to_index)
print("\nMapping from number to name:")
print(index_to_label)

# Read train_csv
import pandas as pd
# Read train.csv
train_data = pd.read_csv(train_csv)

# Print the first five rows of the train_data DataFrame
print(train_data.head())

batch_size = 32
epochs = 10
workers = 0 if os.name == 'nt' else 2

device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
print('Running on device: {}'.format(device))

class Mydataset(Dataset):
  def __init__(self, csv_file, images_dir, index_map, transform=None):
    self.images_dir = images_dir
    self.transform = transform
    self.index_map = index_map # filename to name

    # Load the CSV file into a DataFrame
    label_frame = pd.read_csv(csv_file)

    # Create a dictionary to map filenames to labels
    self.label_dict = pd.Series(label_frame.Category.values,
                      index=label_frame['File Name']).to_dict()

    # List all jpg files
    self.filenames = [f for f in os.listdir(images_dir) if f.endswith('.jpg')]

    # Find filenames to only in the CSV file
    self.filenames = [f for f in self.filenames if f in self.label_dict]

  def __len__(self):
    return len(self.filenames)

  def __getitem__(self, idx):
    filename = self.filenames[idx]
    img_path = os.path.join(self.images_dir, filename)
    image = Image.open(img_path).convert("RGB")

    label = self.index_map[self.label_dict[filename]]

    if self.transform:
      image = self.transform(image)

    return image, label

# transform
train_transform= transforms.Compose([
  transforms.Resize((224, 224)),
  transforms.ToTensor(),
  torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])
])

train_dataset = Mydataset(csv_file= train_csv, images_dir=train_data_path,
                      index_map=label_to_index, transform=train_transform)

image_data = np.arange(len(train_dataset))
np.random.shuffle(image_data)
train_data = image_data[:int(0.8 * len(image_data))] # 80% of data used for train
valid_data = image_data[int(0.8 * len(image_data)):] # 20% of data used for validation

# data loaders
def collate_fn(batch):
  images = []
  labels = []

  for img, label in batch:
    images.append(img)
    labels.append(label[0]) # get the first element of the label tuple

  return torch.stack(images, 0), torch.tensor(labels)

random_indices = torch.randperm(len(train_data)) # change the order of training data

train_loader = DataLoader(
    train_dataset,
    num_workers=workers,
    batch_size=batch_size,
    shuffle=True,
    # collate_fn=collate_fn
)

random_indices = torch.randperm(len(valid_data)) # change the order of validation data
val_loader = DataLoader(
    valid_data,
    num_workers=workers,
    batch_size=batch_size,
    shuffle=True,
    # collate_fn=collate_fn
)

import torchvision.models as models

# Load the pre-trained ResNet50 model
model = models.resnet50(pretrained=True)

# Freeze the model parameters
for param in model.parameters():
  param.requires_grad = False

# Change the final fully connected layer
model.fc = nn.Linear(2048, len(label_to_index))

# Move the model to the device
model.to(device)

# Print the model
print(model)

# prompt: Combine the training step and validation step

def train_and_validate(model, train_loader, val_loader, loss_fn, optimizer, epochs):
  for epoch in range(epochs):
    train_loss = 0.0
    model.train()
    for batch, (images, labels) in enumerate(train_loader):
      images, labels = images.to(device), labels.to(device)
      optimizer.zero_grad()
      outputs = model(images)
      loss = loss_fn(outputs, labels)
      loss.backward()
      optimizer.step()
      train_loss += loss.item()

    val_loss = 0.0
    model.eval()
    for batch, (images, labels) in enumerate(val_loader):
      images, labels = images.to(device), labels.to(device)
      outputs = model(images)
      loss = loss_fn(outputs, labels)
      val_loss += loss.item()

    train_loss /= len(train_loader)
    val_loss /= len(val_loader)
    print(f"Epoch {epoch + 1}: Train Loss: {train_loss:.3f}, Val Loss: {val_loss:.3f}")

# Define the loss function and optimizer
loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# Train and validate the model
train_and_validate(model, train_loader, val_loader, loss_fn, optimizer, epochs)

# prompt: Using resnet50 for the training model

import torch
import torchvision
import torchvision.transforms as transforms

# Load the pre-trained ResNet50 model
model = torchvision.models.resnet50(pretrained=True)
model.to(device)

# Set the model to training mode
model.train()

# Define the loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# Train the model
for epoch in range(epochs):
  for i, (images, labels) in enumerate(train_loader):
    # Move tensors to the configured device
    images = images.to(device)
    labels = labels.to(device)

    # Forward pass
    outputs = model(images)
    loss = criterion(outputs, labels)

    # Backward pass and optimize
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    # Print statistics
    if (i + 1) % 100 == 0:
      print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(
        epoch + 1, epochs, i + 1, len(train_loader), loss.item()))

    torch.save(model.state_dict(), f'resnet50_{epoch}.pt')

# Save the trained model
torch.save(model.state_dict(), 'resnet50.pt')

# prompt: After I trained the model, what next

# Load the trained model
model = torchvision.models.resnet50()
model.load_state_dict(torch.load('resnet50.pt'))
model.to(device)

# Set the model to evaluation mode
model.eval()

# Evaluate the model on the validation data
correct = 0
total = 0
with torch.no_grad():
  for images, labels in val_loader:
    images = images.to(device)
    labels = labels.to(device)
    outputs = model(images)
    _, predicted = torch.max(outputs.data, 1)
    total += labels.size(0)
    correct += (predicted == labels).sum().item()

print('Accuracy of the model : %d %%' % (100 * correct / total))

# prompt: Then, I unzip the test file and run the test data.

!unzip /content/drive/MyDrive/mini_challenge/test_crop.zip
test_data_path = '/content/test_crop'
test_dataset = Mydataset(csv_file= test_csv, images_dir=test_data_path,
                      index_map=label_to_index, transform=train_transform)

test_loader = DataLoader(
    test_dataset,
    num_workers=workers,
    batch_size=batch_size,
    shuffle=True,
    # collate_fn=collate_fn
)

# Load the trained model
model = torchvision.models.resnet50()
model.load_state_dict(torch.load('resnet50.pt'))
model.to(device)

# Set the model to evaluation mode
model.eval()

# Evaluate the model on the test data
correct = 0
total = 0
with torch.no_grad():
  for images, labels in test_loader:
    images = images.to(device)
    labels = labels.to(device)
    outputs = model(images)
    _, predicted = torch.max(outputs.data, 1)
    total += labels.size(0)
    correct += (predicted == labels).sum().item()

print('Accuracy of the model : %d %%' % (100 * correct / total))